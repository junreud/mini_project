{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806b8a34",
   "metadata": {},
   "source": [
    "# ğŸš€ Phase 1: Google Colab í™˜ê²½ êµ¬ì„±\n",
    "\n",
    "## ì´ ë…¸íŠ¸ë¶ì˜ ëª©í‘œ\n",
    "1. Google Colabì—ì„œ GPU ì„¤ì •í•˜ê¸°\n",
    "2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "3. Google Drive ì—°ë™ (ë°ì´í„°/ëª¨ë¸ ì €ì¥ìš©)\n",
    "4. í™˜ê²½ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "---\n",
    "## âš ï¸ ì‹œì‘í•˜ê¸° ì „ì—\n",
    "\n",
    "### Colabì—ì„œ GPU ì„¤ì •í•˜ëŠ” ë²•\n",
    "1. ìƒë‹¨ ë©”ë‰´: **ëŸ°íƒ€ì„(Runtime) â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½(Change runtime type)**\n",
    "2. **í•˜ë“œì›¨ì–´ ê°€ì†ê¸°(Hardware accelerator)**: T4 GPU ì„ íƒ\n",
    "3. **ì €ì¥(Save)** í´ë¦­\n",
    "\n",
    "### ë¬´ë£Œ vs ìœ ë£Œ\n",
    "- **ë¬´ë£Œ**: T4 GPU (16GB VRAM) - í•˜ë£¨ ì‚¬ìš© ì œí•œ ìˆìŒ\n",
    "- **Colab Pro**: ë” ê¸´ ì„¸ì…˜, ë” ì¢‹ì€ GPU (A100 ê°€ëŠ¥)\n",
    "- **ìš°ë¦¬ í”„ë¡œì íŠ¸**: ë¬´ë£Œ T4ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤! âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc050024",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ GPU ì„¤ì • í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfdea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ” í™˜ê²½ ì •ë³´\n",
      "==================================================\n",
      "Python ë²„ì „: 3.13.2\n",
      "PyTorch ë²„ì „: 2.9.0\n",
      "CUDA ë²„ì „: None\n",
      "\n",
      "==================================================\n",
      "ğŸ® GPU ì •ë³´\n",
      "==================================================\n",
      "âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\n",
      "\n",
      "í•´ê²° ë°©ë²•:\n",
      "1. ìƒë‹¨ ë©”ë‰´: ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½\n",
      "2. í•˜ë“œì›¨ì–´ ê°€ì†ê¸°: T4 GPU ì„ íƒ\n",
      "3. ì €ì¥ í›„ ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ” í™˜ê²½ ì •ë³´\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Python ë²„ì „: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ® GPU ì •ë³´\")\n",
    "print(\"=\"*50)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥!\")\n",
    "    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë³´\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"ì „ì²´ GPU ë©”ëª¨ë¦¬: {gpu_memory:.2f} GB\")\n",
    "    \n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬\n",
    "    free_memory = torch.cuda.mem_get_info()[0] / 1e9\n",
    "    print(f\"ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {free_memory:.2f} GB\")\n",
    "    print()\n",
    "    print(\"ğŸ’¡ T4 GPU (16GB)ë©´ 7B ëª¨ë¸ QLoRA í•™ìŠµ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"\\ní•´ê²° ë°©ë²•:\")\n",
    "    print(\"1. ìƒë‹¨ ë©”ë‰´: ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½\")\n",
    "    print(\"2. í•˜ë“œì›¨ì–´ ê°€ì†ê¸°: T4 GPU ì„ íƒ\")\n",
    "    print(\"3. ì €ì¥ í›„ ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc553be7",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Google Drive ì—°ë™\n",
    "\n",
    "í•™ìŠµí•œ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ Google Driveë¥¼ ì—°ê²°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21743788",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Drive ë§ˆìš´íŠ¸\u001b[39;00m\n\u001b[32m      4\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Drive ë§ˆìš´íŠ¸\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nâœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
    "print(\"ğŸ“ ê²½ë¡œ: /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af1e85",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "\n",
    "Driveì— í”„ë¡œì íŠ¸ í´ë”ë¥¼ ë§Œë“¤ì–´ í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73283f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_NAME = \"chatbot_project\"\n",
    "DRIVE_PROJECT_PATH = f\"/content/drive/MyDrive/{PROJECT_NAME}\"\n",
    "\n",
    "# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "directories = [\n",
    "    f\"{DRIVE_PROJECT_PATH}/data/raw\",\n",
    "    f\"{DRIVE_PROJECT_PATH}/data/processed\",\n",
    "    f\"{DRIVE_PROJECT_PATH}/models/checkpoints\",\n",
    "    f\"{DRIVE_PROJECT_PATH}/models/final\",\n",
    "    f\"{DRIVE_PROJECT_PATH}/outputs/logs\",\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"âœ… ìƒì„±: {directory}\")\n",
    "\n",
    "print(f\"\\nğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {DRIVE_PROJECT_PATH}\")\n",
    "print(\"\\nğŸ’¡ í•™ìŠµ ì¤‘ ì„¸ì…˜ì´ ëŠê²¨ë„ Driveì— ì €ì¥ë˜ë¯€ë¡œ ì•ˆì „í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6eeb3",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "### ì„¤ì¹˜ ì‹œê°„: ì•½ 3-5ë¶„ â±ï¸\n",
    "- Colabì€ ë§¤ë²ˆ ìƒˆë¡œìš´ í™˜ê²½ì´ë¯€ë¡œ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- í•œë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture: ì„¤ì¹˜ ë¡œê·¸ë¥¼ ìˆ¨ê¹ë‹ˆë‹¤ (ì†ë„ëŠ” ë™ì¼)\n",
    "# ë¡œê·¸ë¥¼ ë³´ê³  ì‹¶ìœ¼ë©´ ì´ ì¤„ì„ ì‚­ì œí•˜ì„¸ìš”\n",
    "\n",
    "# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "!pip install -q transformers>=4.35.0\n",
    "!pip install -q datasets>=2.14.0\n",
    "!pip install -q peft>=0.6.0\n",
    "!pip install -q bitsandbytes>=0.41.0\n",
    "!pip install -q accelerate>=0.24.0\n",
    "!pip install -q sentencepiece>=0.1.99\n",
    "!pip install -q protobuf>=3.20.0\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f19322",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ì„¤ì¹˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7514130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í™•ì¸\\n\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import peft\n",
    "    import bitsandbytes as bnb\n",
    "    import accelerate\n",
    "    \n",
    "    print(f\"âœ… transformers: {transformers.__version__}\")\n",
    "    print(f\"âœ… datasets: {datasets.__version__}\")\n",
    "    print(f\"âœ… peft: {peft.__version__}\")\n",
    "    print(f\"âœ… bitsandbytes: {bnb.__version__}\")\n",
    "    print(f\"âœ… accelerate: {accelerate.__version__}\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ìœ„ì˜ ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b636e",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‘ì€ í•œêµ­ì–´ ëª¨ë¸ë¡œ ë¡œë”©/ìƒì„±ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5eca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"ğŸ”„ í…ŒìŠ¤íŠ¸ ëª¨ë¸ ë¡œë”© ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)\\n\")\n",
    "\n",
    "# ì‘ì€ í•œêµ­ì–´ ëª¨ë¸ (ì•½ 250MB)\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# GPUë¡œ ì´ë™\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    print(\"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜: {model.num_parameters():,}ê°œ\\n\")\n",
    "\n",
    "# ê°„ë‹¨í•œ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "test_prompt = \"ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ”\"\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "print(\"ğŸ”„ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\\n\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"ì…ë ¥: {test_prompt}\")\n",
    "print(f\"ìƒì„±: {generated}\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nâœ… í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ! í™˜ê²½ì´ ì •ìƒì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a453359",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ê°€ ëë‚¬ìœ¼ë©´ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706eca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì‚­ì œ\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(\"âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5665b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Phase 1 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] GPU (T4) ì„¤ì • ì™„ë£Œ\n",
    "- [ ] GPU ë©”ëª¨ë¦¬ í™•ì¸ (ì•½ 15GB ì‚¬ìš© ê°€ëŠ¥)\n",
    "- [ ] Google Drive ì—°ë™ ì™„ë£Œ\n",
    "- [ ] í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\n",
    "- [ ] í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ\n",
    "- [ ] ëª¨ë¸ ë¡œë”©/ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 2\n",
    "\n",
    "ì´ì œ í™˜ê²½ êµ¬ì„±ì´ ëë‚¬ìŠµë‹ˆë‹¤! ë‹¤ìŒì—ëŠ”:\n",
    "\n",
    "1. **ë°ì´í„° ì¤€ë¹„**: í•™ìŠµìš© í•œêµ­ì–´ ëŒ€í™” ë°ì´í„° ë§Œë“¤ê¸°\n",
    "2. **ë°ì´í„° í¬ë§·**: Chat template í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "3. **ë°ì´í„° ì—…ë¡œë“œ**: Google Driveì— ì €ì¥\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Colab ì‚¬ìš© íŒ\n",
    "\n",
    "### ì„¸ì…˜ ìœ ì§€í•˜ê¸°\n",
    "- ë¬´ë£Œ Colabì€ ì•½ 12ì‹œê°„ í›„ ì„¸ì…˜ì´ ëŠê¹ë‹ˆë‹¤\n",
    "- í•™ìŠµ ì¤‘ì—ëŠ” íƒ­ì„ ë‹«ì§€ ë§ˆì„¸ìš”\n",
    "- Google Driveì— ìë™ ì €ì¥ë˜ë¯€ë¡œ ì²´í¬í¬ì¸íŠ¸ëŠ” ì•ˆì „í•©ë‹ˆë‹¤\n",
    "\n",
    "### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ\n",
    "```python\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "### GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "### ì¤‘ìš” íŒŒì¼ì€ Driveì— ì €ì¥\n",
    "- `/content/`ëŠ” ì„¸ì…˜ì´ ëŠê¸°ë©´ ì‚­ì œë©ë‹ˆë‹¤\n",
    "- `/content/drive/MyDrive/`ì— ì €ì¥í•˜ì„¸ìš”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
