{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb67914",
   "metadata": {},
   "source": [
    "# Phase 1: 환경 구성 체크\n",
    "\n",
    "## 목표\n",
    "- Python 환경 확인\n",
    "- GPU 사용 가능 여부 확인\n",
    "- 필수 라이브러리 설치 및 테스트\n",
    "- Hugging Face 기본 사용법 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029451a",
   "metadata": {},
   "source": [
    "## 1. 기본 환경 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca32640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 버전: 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "운영체제: Darwin 25.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(f\"Python 버전: {sys.version}\")\n",
    "print(f\"운영체제: {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bf64b",
   "metadata": {},
   "source": [
    "## 2. PyTorch & GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ab3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.9.0\n",
      "CUDA 사용 가능: False\n",
      "⚠️ GPU를 사용할 수 없습니다. CPU로 진행하거나 Colab을 사용하세요.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU를 사용할 수 없습니다. CPU로 진행하거나 Colab을 사용하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c4d0",
   "metadata": {},
   "source": [
    "## 3. 필수 라이브러리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import 테스트\n",
    "try:\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import peft\n",
    "    import bitsandbytes\n",
    "    import accelerate\n",
    "    \n",
    "    print(\"✅ 모든 필수 라이브러리가 설치되었습니다!\")\n",
    "    print(f\"transformers: {transformers.__version__}\")\n",
    "    print(f\"datasets: {datasets.__version__}\")\n",
    "    print(f\"peft: {peft.__version__}\")\n",
    "    print(f\"accelerate: {accelerate.__version__}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ 라이브러리 설치 필요: {e}\")\n",
    "    print(\"\\n설치 명령어:\")\n",
    "    print(\"pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aafa35",
   "metadata": {},
   "source": [
    "## 4. 간단한 모델 로딩 테스트 (작은 모델)\n",
    "\n",
    "본격적인 학습 전에 작은 모델로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 작은 테스트 모델 (약 250MB)\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "\n",
    "print(\"모델 로딩 중...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(f\"✅ 모델 로딩 성공!\")\n",
    "print(f\"파라미터 수: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b9de9",
   "metadata": {},
   "source": [
    "## 5. 간단한 텍스트 생성 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65be282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 생성 테스트\n",
    "text = \"인공지능은\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.8,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"입력: {text}\")\n",
    "print(f\"생성: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d1e1",
   "metadata": {},
   "source": [
    "## ✅ Phase 1 체크리스트\n",
    "\n",
    "- [ ] Python 3.8+ 설치 확인\n",
    "- [ ] GPU 사용 가능 (또는 Colab 준비)\n",
    "- [ ] 필수 라이브러리 설치 완료\n",
    "- [ ] 간단한 모델 로딩/생성 성공\n",
    "\n",
    "## 다음 단계\n",
    "Phase 2에서는 실제로 사용할 데이터를 준비합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
